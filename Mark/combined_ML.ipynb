{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbee52eb-c94a-481e-ad7a-7afe35ad7989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.panel_extension: A HoloViz extension was loaded previously. This means the extension is already initialized and the following Panel extensions could not be properly loaded: ['plotly']. If you are loading custom extensions with pn.extension(...) ensure that this is called before any other HoloViz extension such as hvPlot or HoloViews.\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import panel as pn\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from yahoofinancials import YahooFinancials\n",
    "import json\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from panel.interact import interact\n",
    "import hvplot.pandas\n",
    "import plotly.express as px\n",
    "pn.extension(\"plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ecabbd9-d100-4d12-80d8-13d95ad63f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Functions\n",
    "# Use newsapi client to get most relevant 20 headlines per day in the past month\n",
    "def get_headlines(keyword,fdate,edate):\n",
    "    all_headlines = []\n",
    "    all_contents = []\n",
    "    all_dates = [] \n",
    "    # string conversion of dates passed in to function\n",
    "    fdate_str=str(fdate.strftime(\"%Y-%m-%d\"))\n",
    "    edate_str=str(edate.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    print(f\"Fetching news about '{keyword}'\")\n",
    "    print(\"*\" * 30)\n",
    "    #while date > end_date:\n",
    "    print(f\"retrieving news from: {fdate} - {edate}\")\n",
    "    articles = newsapi.get_everything(\n",
    "        q=keyword,\n",
    "        # from_param=str(date)[:10],\n",
    "        # to=str(date)[:10],\n",
    "        from_param=fdate_str,\n",
    "        to=edate_str,\n",
    "        language=\"en\",\n",
    "        sort_by=\"relevancy\",\n",
    "        page=1,\n",
    "    )\n",
    "    headlines = []\n",
    "    contents = []\n",
    "    for i in range(0, len(articles[\"articles\"])):\n",
    "        headlines.append(articles[\"articles\"][i][\"title\"])\n",
    "        contents.append(articles[\"articles\"][i][\"content\"])\n",
    "    all_headlines.append(headlines)\n",
    "    all_contents.append(contents)\n",
    "    all_dates.append(fdate)\n",
    "    #date = date - timedelta(weeks=1)\n",
    "    return all_headlines, all_dates, all_contents\n",
    "\n",
    "# Create function that computes average compound sentiment of headlines for each day\n",
    "def headline_sentiment_summarizer_avg(data,sdate):\n",
    "    df=data.copy()\n",
    "    sentiment = []\n",
    "    sentiment_pos = []\n",
    "    sentiment_neg = []\n",
    "    for day in data:\n",
    "        day_score = []\n",
    "        day_positive = []\n",
    "        day_negative = []\n",
    "        for h in day:\n",
    "            \n",
    "            if h == None:\n",
    "                continue\n",
    "            else:\n",
    "                day_score.append(sid.polarity_scores(h)[\"compound\"])\n",
    "                day_positive.append(sid.polarity_scores(h)[\"pos\"])\n",
    "                day_negative.append(sid.polarity_scores(h)[\"neg\"])\n",
    "        sentiment.append(sum(day_score) / len(day_score))\n",
    "        sentiment_pos.append(sum(day_positive) / len(day_positive))\n",
    "        sentiment_neg.append(sum(day_negative) / len(day_negative))\n",
    "    d={\"c0\":sentiment,\"p0\":sentiment_pos,\"n0\":sentiment_neg,\"Date\":str(sdate.strftime(\"%Y-%m-%d\"))}\n",
    "    sentiment_df=pd.DataFrame(data=d).set_index(\"Date\")\n",
    "    return sentiment_df #, sentiment_pos, sentiment_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd7eee6-62d4-4748-9724-1c56900193c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call and set API from yahoo financials - crude oil price\n",
    "yahoo_financials = YahooFinancials('CL=F')\n",
    "crude_prices=(yahoo_financials.get_historical_price_data(\"2020-06-01\", \"2022-06-01\", \"weekly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd1c83a-30b3-4497-820b-138a03f118ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set json object and write crrude prices to json\n",
    "json_object= json.dumps(crude_prices['CL=F']['prices'], indent = 4)\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db108c71-bcfb-44a2-823d-4c85af4870fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json\n",
    "crude_prices = pd.read_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95221168-8954-490f-b61f-b807c63fd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for crude prices \n",
    "crude_prices_df = pd.DataFrame(crude_prices)\n",
    "#crude_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5c1ecf-d486-436a-86ca-f2e3eb1d8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns \n",
    "crude_prices_df.drop(['date','high','low','open','adjclose'],axis=1, inplace = True)\n",
    "#crude_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685335da-00a9-4ea6-bd3f-95137e513f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns and set index of dataframe on date\n",
    "crude_prices_df.rename(columns = {'close':'Crude Close', 'volume':'Crude Volume','formatted_date':'Date'}, inplace = True)\n",
    "crude_prices_df.set_index('Date', inplace = True)\n",
    "#crude_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63dd0edc-f6ee-4f9a-ab9d-c17f74feafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call yahoo financial to get gold prices \n",
    "yahoo_financials = YahooFinancials('GC=F')\n",
    "gold_prices=(yahoo_financials.get_historical_price_data(\"2020-06-01\", \"2022-06-01\", \"weekly\"))\n",
    "#print(gold_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0d0f1a-05ed-4dd8-87af-20e748a9c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set json object and write gold prices to json\n",
    "json_object= json.dumps(gold_prices['GC=F']['prices'], indent = 4)\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b70f181-09e6-45e2-94d0-ae9115e11c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json\n",
    "gold_prices = pd.read_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10edada-afc1-4016-b27a-f866f21f2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert gold prices to dataframe\n",
    "gold_prices_df = pd.DataFrame(gold_prices)\n",
    "#gold_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c389bb-755f-44b3-9460-faec3ad088de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns from the data frame\n",
    "gold_prices_df.drop(['date','high','low','open','adjclose'],axis=1, inplace = True)\n",
    "#gold_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69ff152-54d7-45ac-bcac-76b5dbc94eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns and set index to date \n",
    "gold_prices_df.rename(columns = {'close':'Gold Close', 'volume':'Gold Volume','formatted_date':'Date'}, inplace = True)\n",
    "gold_prices_df.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ea88fd-1e5e-4217-be3b-4843f9ee059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call api for SPY s and p 500 data\n",
    "yahoo_financials = YahooFinancials('SPY')\n",
    "SPY_prices=(yahoo_financials.get_historical_price_data(\"2020-06-01\", \"2022-06-01\", \"weekly\"))\n",
    "#print(SPY_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d2ae9a-c686-4f13-a6c7-705c6f29df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set json object and write data \n",
    "json_object= json.dumps(SPY_prices['SPY']['prices'], indent = 4)\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af85efb-28da-44f6-9740-a540c998eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the json data\n",
    "SPY_prices = pd.read_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f9b503-1307-4d42-9aa0-2bcd117074d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert json to a data frame\n",
    "SPY_prices_df = pd.DataFrame(SPY_prices)\n",
    "#SPY_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae4e8e0c-e23c-4a10-b812-05861741bf5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date' 'high' 'low' 'open' 'adjclose'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9252/4204302872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#drop unneedeeed columns, rename columns and set index to date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSPY_prices_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'high'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'low'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'open'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'adjclose'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSPY_prices_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'close'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'SPY Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'formatted_date'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mSPY_prices_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizlearn\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizlearn\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4913\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4914\u001b[0m         )\n\u001b[0;32m   4915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizlearn\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizlearn\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizlearn\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date' 'high' 'low' 'open' 'adjclose'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#drop unneedeeed columns, rename columns and set index to date \n",
    "SPY_prices_df.drop(['date','high','low','open','adjclose','volume'],axis=1, inplace = True)\n",
    "SPY_prices_df.rename(columns = {'close':'SPY Close', 'formatted_date':'Date'}, inplace = True)\n",
    "SPY_prices_df.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f8776b4-455b-4638-935d-e227ab04cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call api and get bitcoin prices \n",
    "yahoo_financials = YahooFinancials('BTC-USD')\n",
    "BTC_prices=(yahoo_financials.get_historical_price_data(\"2020-06-01\", \"2022-06-01\", \"weekly\"))\n",
    "#print(BTC_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5afcc8c7-8728-4a1e-a936-8fcf60aa0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set sson object and write data\n",
    "json_object= json.dumps(BTC_prices['BTC-USD']['prices'], indent = 4)\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00f90702-e03a-496a-bef4-978ca806cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json data\n",
    "BTC_prices = pd.read_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a84f127-db4e-4a67-9367-ee7e0ad0480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Btc data frame\n",
    "BTC_prices_df = pd.DataFrame(BTC_prices)\n",
    "#BTC_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c98ff6-99f4-4fb1-b390-bb6de9dba6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop undeeded columns, rename columns set index of data frame to date\n",
    "BTC_prices_df.drop(['date','high','low','open','adjclose'],axis=1, inplace = True)\n",
    "BTC_prices_df.rename(columns = {'close':'BTC Close', 'volume':'BTC Volume','formatted_date':'Date'}, inplace = True)\n",
    "BTC_prices_df.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad3dc5a1-18bc-469d-9d10-1b36a76d70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call yahoo financial api for eth data\n",
    "yahoo_financials = YahooFinancials('ETH-USD')\n",
    "ETH_prices=(yahoo_financials.get_historical_price_data(\"2020-06-01\", \"2022-06-01\", \"weekly\"))\n",
    "#print(ETH_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "380c6947-291b-4d55-8717-00a15536f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set json obect write data to json\n",
    "json_object= json.dumps(ETH_prices['ETH-USD']['prices'], indent = 4)\n",
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cb82ce0-a0bc-4788-beba-695b5d570622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json data\n",
    "ETH_prices = pd.read_json('sample.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9e07db9-6192-48f9-89bf-25709d71e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create eath data frame\n",
    "ETH_prices_df = pd.DataFrame(ETH_prices)\n",
    "#ETH_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f74ffcfe-fc6a-4935-b8b5-620365c3f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns, rename columns, set index to date\n",
    "ETH_prices_df.drop(['date','high','low','open','adjclose'],axis=1, inplace = True)\n",
    "ETH_prices_df.rename(columns = {'close':'ETH Close', 'volume':'ETH Volume','formatted_date':'Date'}, inplace = True)\n",
    "ETH_prices_df.set_index('Date', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20523d34-86ed-41b2-a9cc-a8ec1b7b86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate asset dataframes into one data frame\n",
    "combined_asset_data = pd.concat([crude_prices_df, gold_prices_df, BTC_prices_df, ETH_prices_df,SPY_prices_df], axis=\"columns\", join=\"inner\")\n",
    "\n",
    "# Adding Features to Predict On to determine if the Asset should move up or down in 2 periods\n",
    "combined_asset_data[ 'SPY UP(2)' ] = combined_asset_data['SPY Close'].diff(periods=2).apply(lambda x: 1 if x <= 0 else 0)\n",
    "combined_asset_data[ 'CRUDE UP(2)' ] = combined_asset_data['Crude Close'].diff(periods=2).apply(lambda x: 1 if x <= 0 else 0)\n",
    "combined_asset_data[ 'GOLD UP(2)' ] = combined_asset_data['Gold Close'].diff(periods=2).apply(lambda x: 1 if x <= 0 else 0)\n",
    "combined_asset_data[ 'BTC UP(2)' ] = combined_asset_data['BTC Close'].diff(periods=2).apply(lambda x: 1 if x <= 0 else 0)\n",
    "combined_asset_data[ 'ETH UP(2)' ] = combined_asset_data['ETH Close'].diff(periods=2).apply(lambda x: 1 if x <= 0 else 0)\n",
    "\n",
    "# Setting Index to datetime to assist with merging with sentiments \n",
    "combined_asset_data.index = pd.to_datetime(combined_asset_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d8220d1-876a-4c13-88c4-9864ec2ee7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fa34132-ac59-484b-ab7c-859671e90142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed \n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "180b91e3-c2ff-4060-b044-279242cb1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This function accepts the column number for the features (X) and the target (y)\n",
    "# # It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# # It returns a numpy array of X any y\n",
    "# def window_data(combined_asset_data, window, feature_col_number, target_col_number):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     for i in range(len(combined_asset_data) - window - 1):\n",
    "#         features = combined_asset_data.iloc[i:(i + window), feature_col_number]\n",
    "#         target = combined_asset_data.iloc[(i + window), target_col_number]\n",
    "#         X.append(features)\n",
    "#         y.append(target)\n",
    "#     return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# create feature x and target y dataframes\n",
    "X = combined_asset_data.iloc[:, 0:8]\n",
    "y = combined_asset_data.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a308636-6694-4450-99dc-d974f6c6f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict Closing Prices using a 10 day window of previous closing prices\n",
    "\n",
    "# feature_column = 1\n",
    "# target_column = 1\n",
    "# X, y = window_data(combined_asset_data, window_size, feature_column, target_column)\n",
    "\n",
    "# Scale the data of the features set using the StandardScaler, imports \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "#set scalare to standard scaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler().fit(X)\n",
    "# X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a95c2fe-e82d-41a7-b581-c5f7b1250348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use 70% of the data for training and the remaineder for testing\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76472343-0f73-4aaf-a885-8eec564dc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fit the Scaler object with the features data X\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# # Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Fit theScaler object with the target data Y\n",
    "scaler.fit(y_train)\n",
    "\n",
    "# # Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "410f018a-8c95-4ac2-845a-d678cfaf35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras models and layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "# Create a shallow, 1 hidden layer, neural network\n",
    "nn = Sequential()\n",
    "\n",
    "# Hidden layer\n",
    "nn.add(Dense(units=2, input_dim=8, activation=\"relu\"))\n",
    "nn.add(Dense(units=2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46fc6990-4df0-4e4a-8826-aac916b3b527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 79ms/step - loss: 0.2737 - mse: 0.2737 - val_loss: 0.5904 - val_mse: 0.5904\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2720 - mse: 0.2720 - val_loss: 0.5870 - val_mse: 0.5870\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2705 - mse: 0.2705 - val_loss: 0.5838 - val_mse: 0.5838\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2691 - mse: 0.2691 - val_loss: 0.5805 - val_mse: 0.5805\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2676 - mse: 0.2676 - val_loss: 0.5773 - val_mse: 0.5773\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2661 - mse: 0.2661 - val_loss: 0.5740 - val_mse: 0.5740\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2647 - mse: 0.2647 - val_loss: 0.5708 - val_mse: 0.5708\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2631 - mse: 0.2631 - val_loss: 0.5677 - val_mse: 0.5677\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2619 - mse: 0.2619 - val_loss: 0.5645 - val_mse: 0.5645\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2605 - mse: 0.2605 - val_loss: 0.5613 - val_mse: 0.5613\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model set epochs\n",
    "model_1 = nn.fit(X, y, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6b6dc-19c8-436b-91db-ab7256a3d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function of the training results for the model\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_1.history[\"loss\"])\n",
    "#plt.plot(model_2.history[\"loss\"])\n",
    "plt.title(\"loss_function - Training -2 hinden layer\")\n",
    "plt.legend([\"1 hidden layer\", \"2 hidden layers\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d63d7a-6ec5-4671-ad81-0897d7d98585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape the features for the model\n",
    "# X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "# X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac077f-c692-4b61-afec-197519ab1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 8\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f621b44-efee-4120-b770-cf4134f68b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d6f7f-d41d-4015-844f-ce6ba141fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4571a6-b740-4de9-ba7f-e191133cade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862817c-4c41-4b2a-92fd-02ca09955e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8ef49-17d2-41d8-b76f-e854feb459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64571669-af14-4536-b288-5c25d10c9d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65eeb1-158e-4684-813d-84eb2ee4dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "assets = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = combined_asset_data.index[-len(real_prices): ]) \n",
    "assets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5ac84-6ab2-4d8d-9b70-8e592847a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "assets.plot(title=\"Actual Vs. Predicted SPY Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02ce34-b151-488a-8787-bbee7e830830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574aea5-0b2c-436f-b4f3-c9efaa149e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizlearn] *",
   "language": "python",
   "name": "conda-env-pyvizlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
