{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10880bf4-b6eb-4e8b-8cc1-da14c2cf274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0327ec-0504-416c-b677-c721dde7e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set News API Key\n",
    "newsapi = NewsApiClient(api_key=os.environ[\"NEWS_API\"])\n",
    "newsapi = NewsApiClient(api_key=os.environ[\"NEWS_API_2\"])\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, api_version='v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d8ffc6c-aba7-4c15-b273-08f2b7245ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use newsapi client to get most relevant 20 headlines per day in the past month\n",
    "def get_headlines(keyword,fdate,edate):\n",
    "    all_headlines = []\n",
    "    all_contents = []\n",
    "    all_dates = []    \n",
    "    # date = datetime.strptime(current_date[:10], \"%Y-%m-%d\")\n",
    "    # end_date = datetime.strptime(past_date[:10], \"%Y-%m-%d\")\n",
    "    print(f\"Fetching news about '{keyword}'\")\n",
    "    print(\"*\" * 30)\n",
    "    #while date > end_date:\n",
    "    print(f\"retrieving news from: {fdate} - {edate}\")\n",
    "    articles = newsapi.get_everything(\n",
    "        q=keyword,\n",
    "        # from_param=str(date)[:10],\n",
    "        # to=str(date)[:10],\n",
    "        from_param=fdate,\n",
    "        to=edate,\n",
    "        language=\"en\",\n",
    "        sort_by=\"relevancy\",\n",
    "        page=1,\n",
    "    )\n",
    "    headlines = []\n",
    "    contents = []\n",
    "    for i in range(0, len(articles[\"articles\"])):\n",
    "        headlines.append(articles[\"articles\"][i][\"title\"])\n",
    "        contents.append(articles[\"articles\"][i][\"content\"])\n",
    "    all_headlines.append(headlines)\n",
    "    all_contents.append(contents)\n",
    "    all_dates.append(fdate+\"-\"+edate)\n",
    "    #date = date - timedelta(weeks=1)\n",
    "    return all_headlines, all_dates, all_contents\n",
    "\n",
    "# Create function that computes average compound sentiment of headlines for each day\n",
    "def headline_sentiment_summarizer_avg(data):\n",
    "    df=data.copy()\n",
    "    sentiment = []\n",
    "    sentiment_pos = []\n",
    "    sentiment_neg = []\n",
    "    for day in data:\n",
    "        day_score = []\n",
    "        day_positive = []\n",
    "        day_negative = []\n",
    "        for h in day:\n",
    "            \n",
    "            if h == None:\n",
    "                continue\n",
    "            else:\n",
    "                day_score.append(sid.polarity_scores(h)[\"compound\"])\n",
    "                day_positive.append(sid.polarity_scores(h)[\"pos\"])\n",
    "                day_negative.append(sid.polarity_scores(h)[\"neg\"])\n",
    "        sentiment.append(sum(day_score) / len(day_score))\n",
    "        sentiment_pos.append(sum(day_positive) / len(day_positive))\n",
    "        sentiment_neg.append(sum(day_negative) / len(day_negative))\n",
    "    return sentiment #, sentiment_pos, sentiment_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cb0ff-7d09-4d4d-9e7c-8cc00f067ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Variable initial values\n",
    "current_date = pd.Timestamp(datetime.now(), tz=\"America/New_York\").isoformat()\n",
    "past_date = pd.Timestamp(datetime.now()- timedelta(7), tz=\"America/New_York\").isoformat()\n",
    "date = datetime.strptime(current_date[:10], \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(past_date[:10], \"%Y-%m-%d\")\n",
    "\n",
    "# Instantiate SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c2bd885-21b7-47f3-96ad-b87cdd419876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news about 'bitcoin'\n",
      "******************************\n",
      "retrieving news from: 2020-06-01 - 2022-06-07\n"
     ]
    },
    {
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'parameterInvalid', 'message': 'You are trying to request results too far in the past. Your plan permits you to request articles as far back as 2022-05-22, but you have requested 2020-06-01. You may need to upgrade to a paid plan.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1856/764827568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbtc_headlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbtc_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbtc_contents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bitcoin\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"2020-06-01\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"2022-06-07\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# eth_headlines, eth_dates = get_headlines(\"ethereum\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# gold_headlines, gold_dates = get_headlines(\"gold\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# crude_oil_headlines, crude_oil_dates, crude_oil_contents = get_headlines(\"crude oil\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# sp500_headlines, sp500_dates = get_headlines(\"S&P 500\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1856/3283262296.py\u001b[0m in \u001b[0;36mget_headlines\u001b[1;34m(keyword, fdate, edate)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0msort_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relevancy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     \u001b[0mheadlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizlearn\\lib\\site-packages\\newsapi\\newsapi_client.py\u001b[0m in \u001b[0;36mget_everything\u001b[1;34m(self, q, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# Check Status of Request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNewsAPIException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'parameterInvalid', 'message': 'You are trying to request results too far in the past. Your plan permits you to request articles as far back as 2022-05-22, but you have requested 2020-06-01. You may need to upgrade to a paid plan.'}"
     ]
    }
   ],
   "source": [
    "btc_headlines, btc_dates, btc_contents = get_headlines(\"bitcoin\",\"2020-06-01\",\"2022-06-07\")\n",
    "# eth_headlines, eth_dates = get_headlines(\"ethereum\")\n",
    "# gold_headlines, gold_dates = get_headlines(\"gold\")\n",
    "# crude_oil_headlines, crude_oil_dates, crude_oil_contents = get_headlines(\"crude oil\")\n",
    "# sp500_headlines, sp500_dates = get_headlines(\"S&P 500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33f1a8f1-c735-4166-a8d8-5aec4a76db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#btc_avg_compound_sentiment,btc_avg_pos_sentiment,btc_neg_sentiment = headline_sentiment_summarizer_avg(btc_contents)\n",
    "btc_avg_compound_sentiment = headline_sentiment_summarizer_avg(btc_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6dfaab98-fe34-435d-892e-8d48dd101719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.041544999999999985]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_avg_compound_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11791c1-c10d-415f-9c91-d99c81d9770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55980c33-a29a-4438-8ded-70157e2838aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizlearn] *",
   "language": "python",
   "name": "conda-env-pyvizlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
